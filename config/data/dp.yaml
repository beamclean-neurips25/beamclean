batch_size: 1

name: openorca
noise_function: "constant"
parquet_file_path: "data/open_orca_testing_dataset_small.parquet"
candidate_token_ids_path: data/candidate_token_ids_big.npy # data/candidate_token_ids.npy

# batch_col: "batch_id"
# batch_inner_col: "_inner_batch_idx"

truncated_seq_len: 32
max_num_samples: -1

# If you want to use precomputed noisy embeddings, set this to the path of the embeddings
noisy_embeddings_path: null # "data/open_orca_testing_dataset_small_embeddings_512.npy"
load_noisy_embeddings: false

# Path to the language model
lm_path: "/models/jay/llama3_2/LLama-3.2-1B-Instruct" # "../LLama-3.2-1B-Instruct"
vocab_size: 128256
embedding_dim: 2048

# Path to the embedding model
embedding_model_path:  "/models/jay/llama3_2/LLama-3.2-1B-Instruct" # "../LLama-3.2-1B-Instruct"  # "gpt2-medium"
translation_dict_path: data/translation/gpt2_llama_translation.json

# Parameters for the constant noise function
const_noise_params:
  # The true mean and variance of the noise for the non-axial case
  true_mean: 0.0
  true_variance: 0.05
  initial_mean: 0.0
  initial_variance: 0.001
  # Seed for the random number generator
  seed: 42
  # If you want to load the mean and variance from a file, set this to true
  load_from_file: false
  mean_file: "data/small_dataset_means.npy"
  var_file: "data/small_dataset_vars.npy"