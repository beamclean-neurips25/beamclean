noise_function: "constant"
candidate_token_ids_path: "data/candidate_tokens/candidate_token_ids_union_big_mrpc.npy" # data/candidate_tokens/candidate_token_ids_gpt2_mrpc.npy  # data/candidate_token_ids_big.npy # data/candidate_token_ids.npy

# If you want to use precomputed noisy embeddings, set this to the path of the embeddings
noisy_embeddings_path: data/input_based_noise # null # "data/open_orca_testing_dataset_small_embeddings_512.npy"
load_noisy_embeddings: false

# Path to the language model
lm_path: "/models/jay/llama3_2/LLama-3.2-1B-Instruct" # "../LLama-3.2-1B-Instruct"
vocab_size: 128256
embedding_dim: 2048

# Path to the embedding model
embedding_model_path: "gpt2-medium" # "../LLama-3.2-1B-Instruct"  # "gpt2-medium"
translation_dict_path: data/translation/gpt2_llama_translation.json


# Parameters for the constant noise function
const_noise_params:
  noise_dist: "isotropic_laplacian" # "laplacian" # "laplacian" # "gaussian"
  # The true mean and variance of the noise for the non-axial case
  true_mean: 0.00
  true_variance: 0.3 # 0.05
  initial_mean: 0.00
  initial_variance: 1e0 # 0.01
  eta: 4000
  # Seed for the random number generator
  seed: 42
  # If you want to load the mean and variance from a file, set this to true
  load_from_file: false
  mean_file: "data/small_dataset_means.npy"
  var_file: "data/small_dataset_vars.npy"
